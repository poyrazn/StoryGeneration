{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nehir/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findtags_prefix(tag_prefix, tagged_text):\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\n",
    "                                  if tag.startswith(tag_prefix))\n",
    "    return dict((tag, cfd[tag].most_common(100)) for tag in cfd.conditions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findtags_exact(exact_tag, tagged_text):\n",
    "\tcfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text if tag == exact_tag)\n",
    "\treturn dict((tag, cfd[tag].most_common(100)) for tag in cfd.conditions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggedcorpusfile = 'taggedcorpus'\n",
    "with open(taggedcorpusfile) as file:\n",
    "\ttaggedwords = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [nltk.tag.str2tuple(t) for t in taggedwords.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "noundict = findtags_exact('NN', tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(text: nltk.Text, word, num=20):\n",
    "\t\t\"\"\"\n",
    "\t\tDistributional similarity: find other words which appear in the\n",
    "\t\tsame contexts as the specified word; list most similar words first.\n",
    "\n",
    "\t\t:param word: The word used to seed the similarity search\n",
    "\t\t:type word: str\n",
    "\t\t:param num: The number of words to generate (default=20)\n",
    "\t\t:type num: int\n",
    "\t\t:seealso: ContextIndex.similar_words()\n",
    "\t\t\"\"\"\n",
    "\t\tif '_word_context_index' not in text.__dict__:\n",
    "\t\t\t# print('Building word-context index...')\n",
    "\t\t\ttext._word_context_index = nltk.ContextIndex(\n",
    "\t\t\t\ttext.tokens, filter=lambda x: x.isalpha(), key=lambda s: s.lower()\n",
    "\t\t\t)\n",
    "\n",
    "\t\t# words = self._word_context_index.similar_words(word, num)\n",
    "\n",
    "\t\tword = word.lower()\n",
    "\t\twci = text._word_context_index._word_to_contexts\n",
    "\t\tif word in wci.conditions():\n",
    "\t\t\tcontexts = set(wci[word])\n",
    "\t\t\tfd = Counter(\n",
    "\t\t\t\tw\n",
    "\t\t\t\tfor w in wci.conditions()\n",
    "\t\t\t\tfor c in wci[w]\n",
    "\t\t\t\tif c in contexts and not w == word\n",
    "\t\t\t)\n",
    "\t\t\twords = [w for w, _ in fd.most_common(num)]\n",
    "\t\t\t# print(nltk.tokenwrap(words))\n",
    "\t\t\treturn words\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tprint(\"No matches\")\n",
    "\t\t\treturn []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjdict = findtags_prefix('JJ', tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NN'])\n"
     ]
    }
   ],
   "source": [
    "nouns = sorted(noundict['NN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs = sorted(adjdict['JJ'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Last', 776), ('able', 3259), ('afraid', 904), ('angry', 851), ('bad', 2474)]\n"
     ]
    }
   ],
   "source": [
    "print(adjs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mother\n"
     ]
    }
   ],
   "source": [
    "example = random.choice(nouns)\n",
    "print(example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag_pairs = nltk.bigrams(tags)\n",
    "adjecs = [a[0] for (a, b) in word_tag_pairs if b[0] == example[0] and a[1] == 'JJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag_pairs = nltk.bigrams(tags)\n",
    "verbs = [a[0] for (a, b) in word_tag_pairs if b[0] == example[0] and (a[1] == 'VB' or a[1] == 'VBD')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag_pairs = nltk.bigrams(tags)\n",
    "nouns = [a[0] for (a, b) in word_tag_pairs if b[0] == example[0] and (a[1] == 'NN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjecs, verbs, nouns = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag_pairs = nltk.bigrams(tags)\n",
    "\n",
    "for (a,b) in word_tag_pairs:\n",
    "    if b[0] == example[0]:\n",
    "        if a[1] == 'JJ':\n",
    "            adjecs.append(a[0])\n",
    "        if a[1] == 'VB' or a[1] == 'VBD':\n",
    "            verbs.append(a[0])\n",
    "        if a[1] == 'NN':\n",
    "            nouns.append(a[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjfd = nltk.FreqDist(adjecs)\n",
    "vbfd = nltk.FreqDist(verbs)\n",
    "nfd = nltk.FreqDist(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mother ---> mom single was birth\n"
     ]
    }
   ],
   "source": [
    "print(example[0], \"--->\", sim[0], adjfd.most_common(1)[0][0], vbfd.most_common(1)[0][0], nfd.most_common(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mom friend friends parents family dad father dog brother son sister\n",
      "teacher wife daughter car boss husband house girlfriend phone\n"
     ]
    }
   ],
   "source": [
    "cor = nltk.Text(word for (word, tag) in tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter, namedtuple\n",
    "sim = similar(cor, example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mother ---> mom single was\n"
     ]
    }
   ],
   "source": [
    "print(example[0], \"--->\", sim[0], adjfd.most_common(1)[0][0], vbfd.most_common(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preceding_adj = [a for (a,b) in word_tag_pairs if b[0] == example]\n",
    "preceding_word_tags = [a[1] for (a,b) in word_tag_pairs if b[0] == 'kid']\n",
    "fdist = nltk.FreqDist(preceding_word_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_fd = nltk.FreqDist(tag for (word, tag) in tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_fd = nltk.FreqDist(word for (word,tag) in tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag_pairs = nltk.bigrams(tags)\n",
    "nountag_preceders = [a[1] for (a, b) in word_tag_pairs if b[1] == 'NN']\n",
    "tagfdist = nltk.FreqDist(nountag_preceders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedset= sorted(set(b for (a, b) in nltk.bigrams(commonwords) if a == 'computer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['will']\n"
     ]
    }
   ],
   "source": [
    "print(sortedset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'PRP': 50572})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd1['he']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_storyline(tags, title):\n",
    "    adjecs, verbs, nouns, advbs = [], [], [], []\n",
    "    word_tag_pairs = nltk.bigrams(tags)\n",
    "    for (a, b) in word_tag_pairs:\n",
    "        if b[0] == title:\n",
    "            if a[1] == 'JJ':\n",
    "                adjecs.append(a[0])\n",
    "            if a[1] == 'VB' or a[1] == 'VBD':\n",
    "                verbs.append(a[0])\n",
    "            if a[1] == 'NN':\n",
    "                nouns.append(a[0])\n",
    "            if a[1] == 'RB':\n",
    "                advbs.append(a[0])\n",
    "\n",
    "    adjfd = nltk.FreqDist(adjecs)\n",
    "    vbfd = nltk.FreqDist(verbs)\n",
    "    nfd = nltk.FreqDist(nouns)\n",
    "    avbfd = nltk.FreqDist(advbs)\n",
    "    #syns = wordnet.synsets(title)\n",
    "    #synonym = syns[0].lemmas()[0].name()\n",
    "    text = nltk.Text(word for (word, tag) in tags)\n",
    "    similar_word = similar(text, title)[0]\n",
    "    if not similar_word:\n",
    "        similar_word = title\n",
    "    storyline = [similar_word, adjfd.most_common(1)[0][0], vbfd.most_common(1)[0][0], nfd.most_common(1)[0][0], avbfd.most_common(1)[0][0]]\n",
    "    return storyline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-360-5f2f6bfef6b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputnouns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstoryline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplan_storyline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" ---> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstoryline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-359-fd11821e2e1b>\u001b[0m in \u001b[0;36mplan_storyline\u001b[0;34m(tags, title)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msimilar_word\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0msimilar_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mstoryline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msimilar_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvbfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavbfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstoryline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "title = random.choice(inputnouns)[0]\n",
    "storyline = plan_storyline(tags, title)\n",
    "print(title, end=\" ---> \")\n",
    "for line in storyline:\n",
    "\tprint(line, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputnouns = sorted(noundict['NN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = nltk.Text(word for (word, tag) in tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dan', 'NNP'), (\"'s\", 'POS'), ('parents', 'NNS'), ('were', 'VBD'), ('overweight', 'JJ'), ('.', '.'), ('Dan', 'NNP'), ('was', 'VBD'), ('overweight', 'VBN'), ('as', 'RB'), ('well', 'RB'), ('.', '.'), ('The', 'DT'), ('doctors', 'NNS'), ('told', 'VBD'), ('his', 'PRP$'), ('parents', 'NNS'), ('it', 'PRP'), ('was', 'VBD'), ('unhealthy', 'JJ'), ('.', '.'), ('His', 'PRP$'), ('parents', 'NNS'), ('understood', 'NN'), ('and', 'CC'), ('decided', 'VBD'), ('to', 'TO'), ('make', 'VB'), ('a', 'DT'), ('change', 'NN'), ('.', '.'), ('They', 'PRP'), ('got', 'VBD'), ('themselves', 'PRP'), ('and', 'CC'), ('Dan', 'NNP'), ('on', 'IN'), ('a', 'DT'), ('diet', 'JJ'), ('.', '.'), ('Carrie', 'NNP'), ('had', 'VBD'), ('just', 'RB'), ('learned', 'VBN'), ('how', 'WRB'), ('to', 'TO'), ('ride', 'VB'), ('a', 'DT'), ('bike', 'NN'), ('.', '.'), ('She', 'PRP'), ('did', 'VBD'), (\"n't\", 'RB'), ('have', 'VB'), ('a', 'DT'), ('bike', 'NN'), ('of', 'IN'), ('her', 'PRP$'), ('own', 'JJ'), ('.', '.'), ('Carrie', 'NNP'), ('would', 'MD'), ('sneak', 'VB'), ('rides', 'NNS'), ('on', 'IN'), ('her', 'PRP$'), ('sister', 'NN'), (\"'s\", 'POS'), ('bike', 'NN'), ('.', '.'), ('She', 'PRP'), ('got', 'VBD'), ('nervous', 'JJ'), ('on', 'IN'), ('a', 'DT'), ('hill', 'NN'), ('and', 'CC'), ('crashed', 'VBD'), ('into', 'IN'), ('a', 'DT'), ('wall', 'NN'), ('.', '.'), ('The', 'DT'), ('bike', 'NN'), ('frame', 'NN'), ('bent', 'NN'), ('and', 'CC'), ('Carrie', 'NNP'), ('got', 'VBD'), ('a', 'DT'), ('deep', 'JJ'), ('gash', 'NN'), ('on', 'IN'), ('her', 'PRP$'), ('leg', 'NN'), ('.', '.'), ('Morgan', 'NNP'), ('enjoyed', 'VBD'), ('long', 'JJ'), ('walks', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "print(tags[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everyone None stopped food None\n",
      "anything notice do order almost\n",
      "baby new were crying excitedly\n",
      "ball foul play soccer dragon\n",
      "beach sandy collect fun None\n",
      "bed new had hospital before\n",
      "bike new go dirt alone\n",
      "birthday happy misspelled surprise None\n",
      "book new was phone immediately\n",
      "boss new None demanding always\n",
      "boy little aged baby ugly\n",
      "boyfriend new became school currently\n",
      "brother little were baby None\n",
      "bus next get school long\n",
      "car new went police extremely\n",
      "cat new bought orange lovely\n",
      "class first skip math long\n",
      "coffee local drink morning n't\n",
      "college local graduated community rather\n",
      "company new had insurance None\n",
      "computer new learn work leather\n",
      "dad elderly saw step especially\n",
      "date first said blind n't\n",
      "daughter old aged baby None\n",
      "day next practiced summer very\n",
      "dinner nice had family almost\n",
      "doctor new made eye then\n",
      "dog new was family ugly\n",
      "door next went car back\n",
      "end other did week n't\n",
      "everyone sure told school Now\n",
      "everything sure tried ate almost\n",
      "family whole visit host basically\n",
      "father real was step None\n",
      "fire small caught house not\n",
      "food fast buy junk fast\n",
      "friend new My school somewhat\n",
      "front cold had beach out\n",
      "fun much had something very\n",
      "game first was video eventually\n",
      "girl little saw baby pretty\n",
      "girlfriend new tell school None\n",
      "hair long cut blonde long\n",
      "help extra needed anyone n't\n",
      "home new went way back\n",
      "hour half lay half eighty\n",
      "house new was beach wore\n",
      "husband new became drunk now\n",
      "ice favorite get chocolate never\n",
      "job new was time first\n",
      "life whole enjoy city still\n",
      "lot whole were parking None\n",
      "lunch picnic had school now\n",
      "man old was homeless None\n",
      "mom single told home luckily\n",
      "money enough save lunch together\n",
      "month next import trial None\n",
      "morning next was tomorrow already\n",
      "mother single was birth sometimes\n",
      "movie scary make horror None\n",
      "music loud loved country really\n",
      "neighbor new None door pretty\n",
      "night last was game all\n",
      "office new took post None\n",
      "one new found work only\n",
      "online videos went research back\n",
      "park local parallel amusement n't\n",
      "party big go birthday away\n",
      "phone new exchanged cell mock\n",
      "pizza frozen ordered order leftover\n",
      "place first took food n't\n",
      "restaurant new made food friendly\n",
      "road long was dirt hilly\n",
      "room new have living enough\n",
      "school high skip law Finally\n",
      "shop local grocery coffee never\n",
      "show favorite enjoy talent n't\n",
      "sister little baby baby None\n",
      "someone sudden saw day Eventually\n",
      "something noticed do order always\n",
      "son old None baby None\n",
      "store local grocery grocery not\n",
      "street busy was side None\n",
      "summer hot was time Then\n",
      "teacher new liked school art\n",
      "team other assign basketball anymore\n",
      "test big was math None\n",
      "time great was part finally\n",
      "today sick work school early\n",
      "town small left home around\n",
      "tree large loved apple holly\n",
      "trip first paid road first\n",
      "water hot drink boiling well\n",
      "way same was half always\n",
      "week last had work very\n",
      "wife new My None None\n",
      "woman old relieved kind lively\n",
      "work hard left school n't\n",
      "yard front did school back\n",
      "year next None school impatiently\n"
     ]
    }
   ],
   "source": [
    "word_tag_pairs = nltk.bigrams(tags)\n",
    "for (word,_) in inputnouns:\n",
    "    adjecs, verbs, nouns, advbs = [], [], [], []\n",
    "    word_tag_pairs = nltk.bigrams(tags)\n",
    "    for (a, b) in word_tag_pairs:\n",
    "        if b[0] == word:\n",
    "            if a[1] == 'JJ':\n",
    "                adjecs.append(a[0])\n",
    "            if a[1] == 'VB' or a[1] == 'VBD':\n",
    "                verbs.append(a[0])\n",
    "            if a[1] == 'NN':\n",
    "                nouns.append(a[0])\n",
    "            if a[1] == 'RB':\n",
    "                advbs.append(a[0])\n",
    "\n",
    "    adjfd = nltk.FreqDist(adjecs)\n",
    "    vbfd = nltk.FreqDist(verbs)\n",
    "    nfd = nltk.FreqDist(nouns)\n",
    "    avbfd = nltk.FreqDist(advbs)\n",
    "    #print(adjfd, vbfd, nfd, avbfd)\n",
    "    if adjfd.most_common(1):\n",
    "        adjdict[word] = adjfd.most_common(1)[0][0]\n",
    "    if vbfd.most_common(1):\n",
    "        vbdict[word] = vbfd.most_common(1)[0][0]\n",
    "    if nfd.most_common(1):\n",
    "        nndict[word] = nfd.most_common(1)[0][0]\n",
    "    if avbfd.most_common(1):\n",
    "        avbdict[word] = avbfd.most_common(1)[0][0]\n",
    "    print(word, adjdict.get(word), vbdict.get(word), nndict.get(word), avbdict.get(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(word for (word, tag) in tags)\n",
    "similardict = {}\n",
    "for (word,_) in inputnouns:\n",
    "    similar_word = similar(text, word)[0]\n",
    "    similardict[word] = similar_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Everyone', 'anything', 'baby', 'ball', 'beach', 'bed', 'bike', 'birthday', 'book', 'boss', 'boy', 'boyfriend', 'brother', 'bus', 'car', 'cat', 'class', 'coffee', 'college', 'company', 'computer', 'dad', 'date', 'daughter', 'day', 'dinner', 'doctor', 'dog', 'door', 'end', 'everyone', 'everything', 'family', 'father', 'fire', 'food', 'friend', 'front', 'fun', 'game', 'girl', 'girlfriend', 'hair', 'help', 'home', 'hour', 'house', 'husband', 'ice', 'job', 'life', 'lot', 'lunch', 'man', 'mom', 'money', 'month', 'morning', 'mother', 'movie', 'music', 'neighbor', 'night', 'office', 'one', 'online', 'park', 'party', 'phone', 'pizza', 'place', 'restaurant', 'road', 'room', 'school', 'shop', 'show', 'sister', 'someone', 'something', 'son', 'store', 'street', 'summer', 'teacher', 'team', 'test', 'time', 'today', 'town', 'tree', 'trip', 'water', 'way', 'week', 'wife', 'woman', 'work', 'yard', 'year'])\n"
     ]
    }
   ],
   "source": [
    "print(similardict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjdict = {}\n",
    "vbdict = {}\n",
    "nndict = {}\n",
    "avbdict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"similardict.pkl\",\"rb\")\n",
    "deneme = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"similardict.pkl\",\"wb\")\n",
    "pickle.dump(similardict,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "word_tag_pairs = nltk.bigrams(tags)\n",
    "print(type(word_tag_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bigram_pairs = [(a,b) for (a,b) in word_tag_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [word[0] for word in inputnouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Everyone', 'anything', 'baby', 'ball', 'beach', 'bed', 'bike', 'birthday', 'book', 'boss', 'boy', 'boyfriend', 'brother', 'bus', 'car', 'cat', 'class', 'coffee', 'college', 'company', 'computer', 'dad', 'date', 'daughter', 'day', 'dinner', 'doctor', 'dog', 'door', 'end', 'everyone', 'everything', 'family', 'father', 'fire', 'food', 'friend', 'front', 'fun', 'game', 'girl', 'girlfriend', 'hair', 'help', 'home', 'hour', 'house', 'husband', 'ice', 'job', 'life', 'lot', 'lunch', 'man', 'mom', 'money', 'month', 'morning', 'mother', 'movie', 'music', 'neighbor', 'night', 'office', 'one', 'online', 'park', 'party', 'phone', 'pizza', 'place', 'restaurant', 'road', 'room', 'school', 'shop', 'show', 'sister', 'someone', 'something', 'son', 'store', 'street', 'summer', 'teacher', 'team', 'test', 'time', 'today', 'town', 'tree', 'trip', 'water', 'way', 'week', 'wife', 'woman', 'work', 'yard', 'year']\n"
     ]
    }
   ],
   "source": [
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cho = np.random.choice(titles, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['restaurant' 'end' 'fun' 'trip' 'street']\n"
     ]
    }
   ],
   "source": [
    "print(cho)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
